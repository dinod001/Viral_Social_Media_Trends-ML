{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c18a3e41",
   "metadata": {},
   "source": [
    "### 01. Import Dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e2ed229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error,root_mean_squared_error,mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import (\n",
    "                                    KFold, \n",
    "                                    GridSearchCV\n",
    "                                    )\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff281f",
   "metadata": {},
   "source": [
    "### 02. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01127a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('../../EDA/artifacts/linear/X_train_reg.npz')['arr_0']\n",
    "X_test = np.load('../../EDA/artifacts/linear/X_test_reg.npz')['arr_0']\n",
    "Y_train = np.load('../../EDA/artifacts/linear/Y_train_reg.npz')['arr_0']\n",
    "Y_test = np.load('../../EDA/artifacts/linear/Y_test_reg.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b97a693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e20394",
   "metadata": {},
   "source": [
    "### 03. Define Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67eb0b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "lr_param_grid = {\n",
    "     'fit_intercept': [True, False],\n",
    "     'n_jobs': [1,5,10,15,None], \n",
    "      'positive': [True,False]\n",
    "}\n",
    "\n",
    "# Random Forest Regressor\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [8, 12, 16],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "\n",
    "# XGBoost Regressor\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [6, 8, 10],\n",
    "    'subsample': [0.8, 1]\n",
    "}\n",
    "\n",
    "# Combine into a single dictionary\n",
    "param_grids = {\n",
    "    'Linear Regression': lr_param_grid,\n",
    "    'Random Forest': rf_param_grid,\n",
    "    'XGBoost': xgb_param_grid\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3294d86",
   "metadata": {},
   "source": [
    "### 04. Define Multi Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04764bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d8da6a",
   "metadata": {},
   "source": [
    "### 05. Configure K-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26e71955",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(\n",
    "    n_splits=6,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "880276e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuning Linear Regression ---\n",
      "Fitting gridSearchCV for Linear Regression\n",
      "Fitting 6 folds for each of 20 candidates, totalling 120 fits\n",
      "Linear Regression gridSearchCV completed ...\n",
      "Best parameters: {'fit_intercept': True, 'n_jobs': 1, 'positive': True}\n",
      "Best CV score: -0.013613487170770303\n",
      "Saved best model for Linear Regression at: ./trained_models\\Linear_Regression_best_model.joblib\n",
      "\n",
      "--- Tuning Random Forest ---\n",
      "Fitting gridSearchCV for Random Forest\n",
      "Fitting 6 folds for each of 18 candidates, totalling 108 fits\n",
      "Random Forest gridSearchCV completed ...\n",
      "Best parameters: {'max_depth': 8, 'min_samples_leaf': 5, 'n_estimators': 200}\n",
      "Best CV score: -0.015634133289016233\n",
      "Saved best model for Random Forest at: ./trained_models\\Random_Forest_best_model.joblib\n",
      "\n",
      "--- Tuning XGBoost ---\n",
      "Fitting gridSearchCV for XGBoost\n",
      "Fitting 6 folds for each of 36 candidates, totalling 216 fits\n",
      "XGBoost gridSearchCV completed ...\n",
      "Best parameters: {'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Best CV score: -0.04710873025016826\n",
      "Saved best model for XGBoost at: ./trained_models\\XGBoost_best_model.joblib\n"
     ]
    }
   ],
   "source": [
    "grid_search_results={}\n",
    "model_dir = './trained_models'\n",
    "\n",
    "for model_name, model in models.items():\n",
    "\n",
    "    print(f\"\\n--- Tuning {model_name} ---\")\n",
    "\n",
    "    param_grid = param_grids[model_name]\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "                estimator=model,\n",
    "                param_grid=param_grid,\n",
    "                cv=cv,\n",
    "                scoring='r2',  # <--- Use a regression metric\n",
    "                verbose=1,\n",
    "                return_train_score=False\n",
    "        )\n",
    "\n",
    "    \n",
    "    print(f\"Fitting gridSearchCV for {model_name}\")\n",
    "\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "\n",
    "    grid_search_results[model_name] = grid_search\n",
    "    \n",
    "    print(f\"{model_name} gridSearchCV completed ...\")\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV score: {grid_search.best_score_}\")\n",
    "\n",
    "     # Save the best trained model to joblib\n",
    "    model_path = os.path.join(model_dir, f\"{model_name.replace(' ', '_')}_best_model.joblib\")\n",
    "    joblib.dump(grid_search.best_estimator_, model_path)\n",
    "    print(f\"Saved best model for {model_name} at: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929996c9",
   "metadata": {},
   "source": [
    "### 06. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e87ac4b",
   "metadata": {},
   "source": [
    "#### 6.1 Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ccc13fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = joblib.load('./trained_models/Linear_Regression_best_model.joblib')\n",
    "rf_model = joblib.load('./trained_models/Random_Forest_best_model.joblib')\n",
    "xgb_model = joblib.load('./trained_models/XGBoost_best_model.joblib')\n",
    "\n",
    "# Example predictions\n",
    "lr_preds = lr_model.predict(X_test)\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "xgb_preds = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a4cb29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------R2 Score------------------\n",
      "\n",
      "Linear Regression R²: -0.005828540865275622\n",
      "Random Forest R²: -0.004247784075397609\n",
      "XGBoost R²: -0.05165750433233862\n",
      "\n",
      "-----------------MAE Score------------------\n",
      "\n",
      "Linear Regression MAE: 0.2511910539730476\n",
      "Random Forest MAE: 0.2516645850661472\n",
      "XGBoost MAE: 0.25632327148528106\n",
      "\n",
      "-----------------RMSE Score------------------\n",
      "\n",
      "Linear Regression RMSE: 0.28986014248688\n",
      "Random Forest RMSE: 0.28963228130721724\n",
      "XGBoost RMSE: 0.2963900954163004\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------R2 Score------------------\\n\")\n",
    "print(\"Linear Regression R²:\", r2_score(Y_test, lr_preds))\n",
    "print(\"Random Forest R²:\", r2_score(Y_test, rf_preds))\n",
    "print(\"XGBoost R²:\", r2_score(Y_test, xgb_preds))\n",
    "\n",
    "print(\"\\n-----------------MAE Score------------------\\n\")\n",
    "print(\"Linear Regression MAE:\", mean_absolute_error(Y_test, lr_preds))\n",
    "print(\"Random Forest MAE:\", mean_absolute_error(Y_test, rf_preds))\n",
    "print(\"XGBoost MAE:\", mean_absolute_error(Y_test, xgb_preds))\n",
    "\n",
    "print(\"\\n-----------------RMSE Score------------------\\n\")\n",
    "print(\"Linear Regression RMSE:\", root_mean_squared_error(Y_test, lr_preds))\n",
    "print(\"Random Forest RMSE:\", root_mean_squared_error(Y_test, rf_preds))\n",
    "print(\"XGBoost RMSE:\", root_mean_squared_error(Y_test, xgb_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
