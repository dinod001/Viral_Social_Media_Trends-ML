{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c18a3e41",
   "metadata": {},
   "source": [
    "### 01. Import Dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e2ed229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error,root_mean_squared_error,mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import (\n",
    "                                    KFold, \n",
    "                                    GridSearchCV\n",
    "                                    )\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff281f",
   "metadata": {},
   "source": [
    "### 02. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01127a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('../../EDA/artifacts/linear/X_train_reg.npz')['arr_0']\n",
    "X_test = np.load('../../EDA/artifacts/linear/X_test_reg.npz')['arr_0']\n",
    "Y_train = np.load('../../EDA/artifacts/linear/Y_train_reg.npz')['arr_0']\n",
    "Y_test = np.load('../../EDA/artifacts/linear/Y_test_reg.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e20394",
   "metadata": {},
   "source": [
    "### 03. Define Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67eb0b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "lr_param_grid = {\n",
    "     'fit_intercept': [True, False],\n",
    "     'n_jobs': [1,5,10,15,None], \n",
    "      'positive': [True,False]\n",
    "}\n",
    "\n",
    "# Random Forest Regressor\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [8, 12, 16],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "\n",
    "# XGBoost Regressor\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [6, 8, 10],\n",
    "    'subsample': [0.8, 1]\n",
    "}\n",
    "\n",
    "# Combine into a single dictionary\n",
    "param_grids = {\n",
    "    'Linear Regression': lr_param_grid,\n",
    "    'Random Forest': rf_param_grid,\n",
    "    'XGBoost': xgb_param_grid\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3294d86",
   "metadata": {},
   "source": [
    "### 04. Define Multi Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04764bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d8da6a",
   "metadata": {},
   "source": [
    "### 05. Configure K-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26e71955",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(\n",
    "    n_splits=6,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "880276e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuning Linear Regression ---\n",
      "Fitting gridSearchCV for Linear Regression\n",
      "Fitting 6 folds for each of 20 candidates, totalling 120 fits\n",
      "Linear Regression gridSearchCV completed ...\n",
      "Best parameters: {'fit_intercept': True, 'n_jobs': 1, 'positive': False}\n",
      "Best CV score: -0.00608061576460613\n",
      "Saved best model for Linear Regression at: ./trained_models\\Linear_Regression_best_model.joblib\n",
      "\n",
      "--- Tuning Random Forest ---\n",
      "Fitting gridSearchCV for Random Forest\n",
      "Fitting 6 folds for each of 18 candidates, totalling 108 fits\n",
      "Random Forest gridSearchCV completed ...\n",
      "Best parameters: {'max_depth': 8, 'min_samples_leaf': 5, 'n_estimators': 100}\n",
      "Best CV score: 0.005515327217860781\n",
      "Saved best model for Random Forest at: ./trained_models\\Random_Forest_best_model.joblib\n",
      "\n",
      "--- Tuning XGBoost ---\n",
      "Fitting gridSearchCV for XGBoost\n",
      "Fitting 6 folds for each of 36 candidates, totalling 216 fits\n",
      "XGBoost gridSearchCV completed ...\n",
      "Best parameters: {'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Best CV score: -0.024790728233716013\n",
      "Saved best model for XGBoost at: ./trained_models\\XGBoost_best_model.joblib\n"
     ]
    }
   ],
   "source": [
    "grid_search_results={}\n",
    "model_dir = './trained_models'\n",
    "\n",
    "for model_name, model in models.items():\n",
    "\n",
    "    print(f\"\\n--- Tuning {model_name} ---\")\n",
    "\n",
    "    param_grid = param_grids[model_name]\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "                estimator=model,\n",
    "                param_grid=param_grid,\n",
    "                cv=cv,\n",
    "                scoring='r2',  # <--- Use a regression metric\n",
    "                verbose=1,\n",
    "                return_train_score=False\n",
    "        )\n",
    "\n",
    "    \n",
    "    print(f\"Fitting gridSearchCV for {model_name}\")\n",
    "\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "\n",
    "    grid_search_results[model_name] = grid_search\n",
    "    \n",
    "    print(f\"{model_name} gridSearchCV completed ...\")\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV score: {grid_search.best_score_}\")\n",
    "\n",
    "     # Save the best trained model to joblib\n",
    "    model_path = os.path.join(model_dir, f\"{model_name.replace(' ', '_')}_best_model.joblib\")\n",
    "    joblib.dump(grid_search.best_estimator_, model_path)\n",
    "    print(f\"Saved best model for {model_name} at: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929996c9",
   "metadata": {},
   "source": [
    "### 06. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e87ac4b",
   "metadata": {},
   "source": [
    "#### 6.1 Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ccc13fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './trained_models/Polynomial_Regression_best_model.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./trained_models/Random_Forest_best_model.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./trained_models/XGBoost_best_model.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m poly_model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./trained_models/Polynomial_Regression_best_model.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Example predictions\u001b[39;00m\n\u001b[0;32m      7\u001b[0m lr_preds \u001b[38;5;241m=\u001b[39m lr_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\www\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './trained_models/Polynomial_Regression_best_model.joblib'"
     ]
    }
   ],
   "source": [
    "lr_model = joblib.load('./trained_models/Linear_Regression_best_model.joblib')\n",
    "rf_model = joblib.load('./trained_models/Random_Forest_best_model.joblib')\n",
    "xgb_model = joblib.load('./trained_models/XGBoost_best_model.joblib')\n",
    "poly_model = joblib.load('./trained_models/Polynomial_Regression_best_model.joblib')\n",
    "\n",
    "# Example predictions\n",
    "lr_preds = lr_model.predict(X_test)\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "xgb_preds = xgb_model.predict(X_test)\n",
    "poly_preds = poly_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4cb29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------R2 Score------------------\n",
      "\n",
      "Linear Regression R²: 0.004573511890015092\n",
      "Random Forest R²: -0.007856283524362295\n",
      "XGBoost R²: -0.03673245040292206\n",
      "\n",
      "-----------------MAE Score------------------\n",
      "\n",
      "Linear Regression MAE: 0.2504531455246391\n",
      "Random Forest MAE: 0.2514605615984781\n",
      "XGBoost MAE: 0.2534346334882049\n",
      "\n",
      "-----------------RMSE Score------------------\n",
      "\n",
      "Linear Regression RMSE: 0.28822702367422365\n",
      "Random Forest RMSE: 0.2900209724794159\n",
      "XGBoost RMSE: 0.29414633855740446\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------R2 Score------------------\\n\")\n",
    "print(\"Linear Regression R²:\", r2_score(Y_test, lr_preds))\n",
    "print(\"Random Forest R²:\", r2_score(Y_test, rf_preds))\n",
    "print(\"XGBoost R²:\", r2_score(Y_test, xgb_preds))\n",
    "print(\"Polynomial Regression R²:\", r2_score(Y_test, poly_preds))\n",
    "\n",
    "print(\"\\n-----------------MAE Score------------------\\n\")\n",
    "print(\"Linear Regression MAE:\", mean_absolute_error(Y_test, lr_preds))\n",
    "print(\"Random Forest MAE:\", mean_absolute_error(Y_test, rf_preds))\n",
    "print(\"XGBoost MAE:\", mean_absolute_error(Y_test, xgb_preds))\n",
    "print(\"Polynomial Regression MAE:\", mean_absolute_error(Y_test, poly_preds))\n",
    "\n",
    "print(\"\\n-----------------RMSE Score------------------\\n\")\n",
    "print(\"Linear Regression RMSE:\", root_mean_squared_error(Y_test, lr_preds))\n",
    "print(\"Random Forest RMSE:\", root_mean_squared_error(Y_test, rf_preds))\n",
    "print(\"XGBoost RMSE:\", root_mean_squared_error(Y_test, xgb_preds))\n",
    "print(\"Polynomial Regression RMSE:\", root_mean_squared_error(Y_test, poly_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
